{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7665aa3-4964-474d-ba6c-44914c143cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import generate_filename, update_bq_table\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../myenv.env')\n",
    "\n",
    "BUCKET_NAME = os.getenv(\"BUCKET_NAME\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "GCP_KEY_ID = os.getenv(\"GCP_KEY_ID\")\n",
    "GCP_ACCESS_KEY = os.getenv(\"GCP_ACCESS_KEY\")\n",
    "DATASET = \"nhanes\"\n",
    "\n",
    "bucket_name = 'nhanes_clean'\n",
    "\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ac39d1-70b8-4592-80d1-fce5d5ea4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_duckdb_gcp():\n",
    "    \"\"\"\n",
    "    Configures DuckDB for use with GCP by setting necessary S3 configurations.\n",
    "    Retrieves GCP access keys from environment variables.\n",
    "    Raises EnvironmentError if keys are not found.\n",
    "    \"\"\"\n",
    "    gcp_access_key_id = GCP_KEY_ID\n",
    "    gcp_secret_access_key = GCP_ACCESS_KEY\n",
    "\n",
    "    if not gcp_access_key_id or not gcp_secret_access_key:\n",
    "        logging.error(\"GCP access key or secret key not set in environment variables.\")\n",
    "        raise EnvironmentError(\"GCP keys not found in environment variables.\")\n",
    "\n",
    "    duckdb.sql(\"SET s3_endpoint='storage.googleapis.com';\")\n",
    "    duckdb.sql(f\"SET s3_access_key_id='{gcp_access_key_id}';\")\n",
    "    duckdb.sql(f\"SET s3_secret_access_key='{gcp_secret_access_key}';\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcc6720-9b8d-4ca4-990a-4183b9d37f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql duckdb:///:default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa88307f-428c-4677-9ea8-6af50581c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_df():\n",
    "    \"\"\"\n",
    "    Retrieves metadata dataframe from BigQuery.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame containing metadata information.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT *,\n",
    "        replace(gcs_data_filename,'.XPT','.parquet') as parquet_filename\n",
    "    FROM `{PROJECT_ID}.nhanes.nhanes_file_metadata`\n",
    "    WHERE dataset = 'all-continuous-nhanes'\n",
    "    AND page_component != 'Limited Access'\n",
    "    \"\"\"\n",
    "    return pd.read_gbq(query, \n",
    "                       project_id=PROJECT_ID,\n",
    "                       dialect=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01bedfea-7095-4556-8d88-9d9bbd8e81db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_metadata_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a19d5e1c-7ac4-4b3a-9fcf-d5873a89da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1718dab-b041-49ba-a2d9-75f7ece465c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET METADATA DATAFRAME\n",
    "metadata_df = pd.read_gbq(\n",
    "    \"\"\"SELECT *,\n",
    "    replace(gcs_data_filename,'.XPT','.parquet') as parquet_filename\n",
    "    FROM nhanes.nhanes_file_metadata\n",
    "    WHERE dataset = 'all-continuous-nhanes'\n",
    "    AND page_component != 'Limited Access'\n",
    "    \"\"\",\n",
    "    project_id=\"nhanes-genai\",\n",
    "    dialect=\"standard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d567913-c71d-4683-ab0c-5cebbc4dcacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1efd27-a468-4698-ab9a-6ae953619eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_subset_df = metadata_df[[\"data_file_name\",\"page_component\"]].drop_duplicates()\n",
    "file_subset_df[\"data_file_name\"] = file_subset_df[\"data_file_name\"].str.strip()\n",
    "file_subset_df[\"page_component\"] = file_subset_df[\"page_component\"].str.strip()\n",
    "\n",
    "file_subset_df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "79ecf52e-2f4d-44f3-a39f-a1e60ca26d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_3956/2600076760.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  file_subset_df.sort_values(by=['data_file_name','page_component'])[file_subset_df['data_file_name'].str.contains('Acrylamide')]['data_file_name'].unique().tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Acrylamide & Glycidamide', 'Acrylamide & Glycidamide - Special Sample']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file_subset_df.sort_values(by=['data_file_name','page_component'])[file_subset_df['data_file_name'].str.contains('Acrylamide')]['data_file_name'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb428a95-b02a-456e-8538-5f31864b88c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df11d6ea-46e5-4b7f-bcb8-fb96628fcf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%sql\n",
    "# output_df << SELECT * FROM read_parquet('s3://nhanes_clean/all-continuous-nhanes/data/acculturation_questionnaire_*.parquet',\n",
    "#                                            union_by_name=True,\n",
    "#                                            filename=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "658f0a91-24bb-485b-ba1d-bc4ec71963da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duckdb.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c68b7a-b9db-45fe-a6fe-670f99ff5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_duckdb_gcp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ba69df0-7321-498d-bbf6-f891cc75d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = duckdb.read_parquet('s3://nhanes_clean/all-continuous-nhanes/data/dual_energy_x_ray_absorptiometry_whole_body*.parquet',\n",
    "#                     union_by_name=True,\n",
    "#                     filename=True).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f91aaa62-9a89-49a0-a093-ccd3fe82bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['filename'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c0b48eae-0ec8-48a1-9a9e-11cadf09b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['SEQN'] = df['SEQN'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f08b045-bbef-4485-b54d-3c8210714b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df.columns.tolist():\n",
    "#     if column != 'filename':\n",
    "#         df[column] = df[column].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1029de-be93-4007-92e6-286a5b404661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alias = generate_filename(\"Dietary Supplement Use 30-Day - File 1,\".lower() + \" \" + page_component.lower(),'')\n",
    "# alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65619769-101d-494a-9de3-fa3be685a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df['data_file_name'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a41f65c0-ffcb-44df-a971-555dce6b216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df[(metadata_df['data_file_name'].str.contains('Hepatitis B'))].sort_values(by=['data_file_name','page_component'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7fdaa895-45be-4dd8-82e3-2d0e013875c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_subset_df.sort_values(by='data_file_name').reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f944bf9a-34b3-46b5-b2a5-369c12ba7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_subset_df[file_subset_df['data_file_name'].str.contains(\"Hepatitis B\")]['data_file_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da25cafc-94b7-43c5-8f52-7eed7a4cf8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acculturation_questionnaire_20231110_185042.csv uploaded to nhanes_clean / acculturation_questionnaire/\n",
      "Starting job 09084aac-724b-4c28-a8ed-529c3769db19\n",
      "Job finished.\n",
      "Table Row Count 92158 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albumin_creatinine_urine_laboratory_20231110_185055.csv uploaded to nhanes_clean / albumin_creatinine_urine_laboratory/\n",
      "Starting job 966ac994-c854-403d-9aea-9e2dd16b4824\n",
      "Job finished.\n",
      "Table Row Count 94940 rows.\n",
      "alcohol_use_questionnaire_20231110_185109.csv uploaded to nhanes_clean / alcohol_use_questionnaire/\n",
      "Starting job 2424b5d0-7daa-48ad-be84-e0c0fc86a364\n",
      "Job finished.\n",
      "Table Row Count 62524 rows.\n",
      "alpha_1_acid_glycoprotein_serum_surplus_laboratory_20231110_185116.csv uploaded to nhanes_clean / alpha_1_acid_glycoprotein_serum_surplus_laboratory/\n",
      "Starting job 030ee158-990f-4175-834f-ab20279d4cb6\n",
      "Job finished.\n",
      "Table Row Count 6002 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arsenic_total_urine_laboratory_20231110_185121.csv uploaded to nhanes_clean / arsenic_total_urine_laboratory/\n",
      "Starting job 194cebe8-cfa8-43d7-b17e-4136f109e245\n",
      "Job finished.\n",
      "Table Row Count 13903 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arsenics_speciated_urine_laboratory_20231110_185126.csv uploaded to nhanes_clean / arsenics_speciated_urine_laboratory/\n",
      "Starting job 2e67964c-2355-43ed-a008-9ca0b9346452\n",
      "Job finished.\n",
      "Table Row Count 10624 rows.\n",
      "audiometry_questionnaire_20231110_185135.csv uploaded to nhanes_clean / audiometry_questionnaire/\n",
      "Starting job 875124b8-685d-4a60-97ac-585af5f868d5\n",
      "Job finished.\n",
      "Table Row Count 102027 rows.\n",
      "audiometry_examination_20231110_185153.csv uploaded to nhanes_clean / audiometry_examination/\n",
      "Starting job 0a30c6e3-c5e5-4297-a5d2-bece73618ae7\n",
      "Job finished.\n",
      "Table Row Count 29714 rows.\n",
      "audiometry_acoustic_reflex_examination_20231110_185215.csv uploaded to nhanes_clean / audiometry_acoustic_reflex_examination/\n",
      "Starting job 924d3e89-9139-434a-932c-45d663d34bd6\n",
      "Job finished.\n",
      "Table Row Count 156493 rows.\n",
      "audiometry_wideband_reflectance_examination_20231110_185407.csv uploaded to nhanes_clean / audiometry_wideband_reflectance_examination/\n",
      "Starting job e6e7e043-6bdf-4815-bbdf-ad626b6eae6e\n",
      "Job finished.\n",
      "Table Row Count 23470 rows.\n",
      "Last 10 datasets took 232.0431890487671 seconds\n",
      "blood_pressure_cholesterol_questionnaire_20231110_185434.csv uploaded to nhanes_clean / blood_pressure_cholesterol_questionnaire/\n",
      "Starting job a1d19fe0-a2ce-41c2-8c23-7bd3b347b08a\n",
      "Job finished.\n",
      "Table Row Count 73787 rows.\n",
      "body_measures_examination_20231110_185446.csv uploaded to nhanes_clean / body_measures_examination/\n",
      "Starting job e19f6485-359a-4110-a177-4b383f86db04\n",
      "Job finished.\n",
      "Table Row Count 111066 rows.\n",
      "cardiovascular_health_questionnaire_20231110_185507.csv uploaded to nhanes_clean / cardiovascular_health_questionnaire/\n",
      "Starting job cd41526b-1618-474a-b62a-77c4162e169c\n",
      "Job finished.\n",
      "Table Row Count 42685 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cholesterol_high_density_lipoprotein_hdl_laboratory_20231110_185513.csv uploaded to nhanes_clean / cholesterol_high_density_lipoprotein_hdl_laboratory/\n",
      "Starting job 431aff3b-9c4b-4cfc-912f-c81338ab3311\n",
      "Job finished.\n",
      "Table Row Count 27654 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cholesterol_low_density_lipoproteins_ldl_triglycerides_laboratory_20231110_185520.csv uploaded to nhanes_clean / cholesterol_low_density_lipoproteins_ldl_triglycerides_laboratory/\n",
      "Starting job eeaab540-1890-46d2-875d-ef7afb7e7ce2\n",
      "Job finished.\n",
      "Table Row Count 8126 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cholesterol_total_laboratory_20231110_185528.csv uploaded to nhanes_clean / cholesterol_total_laboratory/\n",
      "Starting job 5ae0953b-6f47-4471-97ec-759a5ad04d36\n",
      "Job finished.\n",
      "Table Row Count 68575 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromium_cobalt_laboratory_20231110_185535.csv uploaded to nhanes_clean / chromium_cobalt_laboratory/\n",
      "Starting job 8f21ddf4-0c60-4f2d-90bc-540c3759d04b\n",
      "Job finished.\n",
      "Table Row Count 13235 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromium_urine_laboratory_20231110_185540.csv uploaded to nhanes_clean / chromium_urine_laboratory/\n",
      "Starting job 2b7b5b60-a674-4c31-88c0-6c93716cd894\n",
      "Job finished.\n",
      "Table Row Count 7869 rows.\n",
      "complete_blood_count_with_5_part_differential_laboratory_20231110_185545.csv uploaded to nhanes_clean / complete_blood_count_with_5_part_differential_laboratory/\n",
      "Starting job 344a3d09-c24f-4735-805b-76df3e2de805\n",
      "Job finished.\n",
      "Table Row Count 8366 rows.\n",
      "complete_blood_count_with_5_part_differential_in_whole_blood_laboratory_20231110_185550.csv uploaded to nhanes_clean / complete_blood_count_with_5_part_differential_in_whole_blood_laboratory/\n",
      "Starting job 234bb84f-75ca-417b-b3d8-1fac7f724a96\n",
      "Job finished.\n",
      "Table Row Count 13772 rows.\n",
      "Last 10 datasets took 318.44487619400024 seconds\n",
      "consumer_behavior_questionnaire_20231110_185558.csv uploaded to nhanes_clean / consumer_behavior_questionnaire/\n",
      "Starting job 6ab94c2f-5e47-4656-b6fa-c65d32212082\n",
      "Job finished.\n",
      "Table Row Count 59842 rows.\n",
      "consumer_behavior_phone_follow_up_module_adult_questionnaire_20231110_185609.csv uploaded to nhanes_clean / consumer_behavior_phone_follow_up_module_adult_questionnaire/\n",
      "Starting job 01aa95dc-69e9-464e-b74b-140d28e69ea7\n",
      "Job finished.\n",
      "Table Row Count 26237 rows.\n",
      "consumer_behavior_phone_follow_up_module_child_questionnaire_20231110_185621.csv uploaded to nhanes_clean / consumer_behavior_phone_follow_up_module_child_questionnaire/\n",
      "Starting job 4b893453-4a14-4fa1-b032-297a84c4b890\n",
      "Job finished.\n",
      "Table Row Count 11426 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cotinine_and_hydroxycotinine_serum_laboratory_20231110_185628.csv uploaded to nhanes_clean / cotinine_and_hydroxycotinine_serum_laboratory/\n",
      "Starting job 77c01477-2dac-4a3c-8e3e-516f918543a5\n",
      "Job finished.\n",
      "Table Row Count 38484 rows.\n",
      "current_health_status_questionnaire_20231110_185639.csv uploaded to nhanes_clean / current_health_status_questionnaire/\n",
      "Starting job 7f8f8488-830d-4ae0-962f-83966c33c1a1\n",
      "Job finished.\n",
      "Table Row Count 102685 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cytomegalovirus_igg_igm_antibodies_serum_laboratory_20231110_185650.csv uploaded to nhanes_clean / cytomegalovirus_igg_igm_antibodies_serum_laboratory/\n",
      "Starting job 541ce115-36aa-421b-b358-a9799aa8869b\n",
      "Job finished.\n",
      "Table Row Count 3640 rows.\n",
      "demographic_variables_and_sample_weights_demographics_20231110_185656.csv uploaded to nhanes_clean / demographic_variables_and_sample_weights_demographics/\n",
      "Starting job fe82e71a-5371-4b83-adee-b5b47ae58fef\n",
      "Job finished.\n",
      "Table Row Count 44960 rows.\n",
      "dermatology_questionnaire_20231110_185712.csv uploaded to nhanes_clean / dermatology_questionnaire/\n",
      "Starting job 1f688c41-77f2-4e50-b782-5d18202a3630\n",
      "Job finished.\n",
      "Table Row Count 43385 rows.\n",
      "diabetes_questionnaire_20231110_185724.csv uploaded to nhanes_clean / diabetes_questionnaire/\n",
      "Starting job 34a5dfb1-7acd-45ee-b3bf-359b8aef9c80\n",
      "Job finished.\n",
      "Table Row Count 111797 rows.\n",
      "diet_behavior_nutrition_questionnaire_20231110_185742.csv uploaded to nhanes_clean / diet_behavior_nutrition_questionnaire/\n",
      "Starting job 13c96827-ebaa-4802-a542-69ea240134de\n",
      "Job finished.\n",
      "Table Row Count 116876 rows.\n",
      "Last 10 datasets took 445.1755156517029 seconds\n",
      "dietary_interview_individual_foods_first_day_dietary_20231110_185827.csv uploaded to nhanes_clean / dietary_interview_individual_foods_first_day_dietary/\n",
      "Starting job eacd4d5e-760f-46e1-92bd-f868fc22b7cf\n",
      "Job finished.\n",
      "Table Row Count 1250769 rows.\n",
      "dietary_interview_individual_foods_second_day_dietary_20231110_190346.csv uploaded to nhanes_clean / dietary_interview_individual_foods_second_day_dietary/\n",
      "Starting job 9bda0550-534b-442d-a709-8721b357ed4a\n",
      "Job finished.\n",
      "Table Row Count 1071858 rows.\n",
      "dietary_interview_total_nutrient_intakes_first_day_dietary_20231110_190800.csv uploaded to nhanes_clean / dietary_interview_total_nutrient_intakes_first_day_dietary/\n",
      "Starting job 74a5ae80-5f92-41e7-bed9-f23439d35a2f\n",
      "Job finished.\n",
      "Table Row Count 91307 rows.\n",
      "dietary_interview_total_nutrient_intakes_second_day_dietary_20231110_190833.csv uploaded to nhanes_clean / dietary_interview_total_nutrient_intakes_second_day_dietary/\n",
      "Starting job e800beb1-8600-46ae-a3c4-ad823013b446\n",
      "Job finished.\n",
      "Table Row Count 91307 rows.\n",
      "'utf-8' codec can't decode byte 0xc9 in position 16: invalid continuation byte\n",
      "Unable to convert data types from bytes to string for: Dietary Interview Technical Support File - Food Codes - Dietary\n",
      "dietary_interview_technical_support_file_food_codes_dietary_20231110_190858.csv uploaded to nhanes_clean / dietary_interview_technical_support_file_food_codes_dietary/\n",
      "Starting job 351d211b-aeea-42ca-a888-75077dc69ad4\n",
      "Job finished.\n",
      "Table Row Count 67662 rows.\n",
      "dietary_supplement_use_24_hour_individual_dietary_supplements_first_day_dietary_20231110_190909.csv uploaded to nhanes_clean / dietary_supplement_use_24_hour_individual_dietary_supplements_first_day_dietary/\n",
      "Starting job 575938c8-d20a-4e0f-a90a-e1ea1c288ae2\n",
      "Job finished.\n",
      "Table Row Count 44463 rows.\n",
      "dietary_supplement_use_24_hour_individual_dietary_supplements_second_day_dietary_20231110_190920.csv uploaded to nhanes_clean / dietary_supplement_use_24_hour_individual_dietary_supplements_second_day_dietary/\n",
      "Starting job bc1d63a3-b0f5-48dc-9e0d-f2e37fb80947\n",
      "Job finished.\n",
      "Table Row Count 43337 rows.\n",
      "dietary_supplement_use_24_hour_total_dietary_supplements_first_day_dietary_20231110_190930.csv uploaded to nhanes_clean / dietary_supplement_use_24_hour_total_dietary_supplements_first_day_dietary/\n",
      "Starting job 8547920b-3a60-4dee-a992-18a13d0ca89c\n",
      "Job finished.\n",
      "Table Row Count 71714 rows.\n",
      "dietary_supplement_use_24_hour_total_dietary_supplements_second_day_dietary_20231110_190947.csv uploaded to nhanes_clean / dietary_supplement_use_24_hour_total_dietary_supplements_second_day_dietary/\n",
      "Starting job 37db59e3-fa2d-4d88-94d5-b6fb179291bc\n",
      "Job finished.\n",
      "Table Row Count 71714 rows.\n",
      "dietary_supplement_use_30_day_individual_dietary_supplements_dietary_20231110_191005.csv uploaded to nhanes_clean / dietary_supplement_use_30_day_individual_dietary_supplements_dietary/\n",
      "Starting job 7fd25772-148a-4807-9fe6-5991109060c0\n",
      "Job finished.\n",
      "Table Row Count 70342 rows.\n",
      "Last 10 datasets took 1180.3978650569916 seconds\n",
      "dietary_supplement_use_30_day_total_dietary_supplements_dietary_20231110_191020.csv uploaded to nhanes_clean / dietary_supplement_use_30_day_total_dietary_supplements_dietary/\n",
      "Starting job 3703d539-c83f-4527-abaf-d520788a7227\n",
      "Job finished.\n",
      "Table Row Count 75402 rows.\n",
      "disability_questionnaire_20231110_191030.csv uploaded to nhanes_clean / disability_questionnaire/\n",
      "Starting job e37c6465-78b9-4c8b-a0f0-c2bb0bd0d2b3\n",
      "Job finished.\n",
      "Table Row Count 28242 rows.\n",
      "drug_use_questionnaire_20231110_191041.csv uploaded to nhanes_clean / drug_use_questionnaire/\n",
      "Starting job 88a2cca7-594f-4b43-96e3-8a8f8713053b\n",
      "Job finished.\n",
      "Table Row Count 41709 rows.\n",
      "early_childhood_questionnaire_20231110_191053.csv uploaded to nhanes_clean / early_childhood_questionnaire/\n",
      "Starting job 3fb40e9a-78b0-4298-bc7a-07013d0912f5\n",
      "Job finished.\n",
      "Table Row Count 43089 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethylene_oxide_laboratory_20231110_191100.csv uploaded to nhanes_clean / ethylene_oxide_laboratory/\n",
      "Starting job 4fbefe49-ede6-4f1a-8809-4720cb1d3101\n",
      "Job finished.\n",
      "Table Row Count 11986 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasting_questionnaire_laboratory_20231110_191110.csv uploaded to nhanes_clean / fasting_questionnaire_laboratory/\n",
      "Starting job 5b86ff13-f562-47b7-af4a-349f7de21d8d\n",
      "Job finished.\n",
      "Table Row Count 106203 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ferritin_laboratory_20231110_191124.csv uploaded to nhanes_clean / ferritin_laboratory/\n",
      "Starting job dcc26707-b3c8-4f28-a54a-854f21fb5e46\n",
      "Job finished.\n",
      "Table Row Count 33176 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flame_retardants_urine_laboratory_20231110_191129.csv uploaded to nhanes_clean / flame_retardants_urine_laboratory/\n",
      "Starting job 9c8fa031-d737-4853-954b-0d1309f46869\n",
      "Job finished.\n",
      "Table Row Count 7915 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folate_rbc_laboratory_20231110_191137.csv uploaded to nhanes_clean / folate_rbc_laboratory/\n",
      "Starting job 24b0d47d-d11f-4b8d-8dee-65131b546b4b\n",
      "Job finished.\n",
      "Table Row Count 41021 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folate_forms_total_individual_serum_laboratory_20231110_191144.csv uploaded to nhanes_clean / folate_forms_total_individual_serum_laboratory/\n",
      "Starting job c7550e0d-216a-4658-bd09-696f0f0868a9\n",
      "Job finished.\n",
      "Table Row Count 41021 rows.\n",
      "Last 10 datasets took 1273.016511440277 seconds\n",
      "food_security_questionnaire_20231110_191155.csv uploaded to nhanes_clean / food_security_questionnaire/\n",
      "Starting job 8e62a6a8-4706-4a41-a5ff-1721ccd0dea3\n",
      "Job finished.\n",
      "Table Row Count 116876 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glycohemoglobin_laboratory_20231110_191215.csv uploaded to nhanes_clean / glycohemoglobin_laboratory/\n",
      "Starting job d26ce792-5d02-4935-8a91-649c761e7fd3\n",
      "Job finished.\n",
      "Table Row Count 79541 rows.\n",
      "health_insurance_questionnaire_20231110_191228.csv uploaded to nhanes_clean / health_insurance_questionnaire/\n",
      "Starting job 009eb132-76ef-47da-b56a-fa5fefd67c30\n",
      "Job finished.\n",
      "Table Row Count 116876 rows.\n",
      "hepatitis_questionnaire_20231110_191240.csv uploaded to nhanes_clean / hepatitis_questionnaire/\n",
      "Starting job 979d3c88-8799-44af-9aac-8d7eb83b6573\n",
      "Job finished.\n",
      "Table Row Count 38035 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hepatitis_a_laboratory_20231110_191248.csv uploaded to nhanes_clean / hepatitis_a_laboratory/\n",
      "Starting job c217e949-855d-4831-8027-d351f6754c3f\n",
      "Job finished.\n",
      "Table Row Count 39630 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hepatitis_b_surface_antibody_laboratory_20231110_191301.csv uploaded to nhanes_clean / hepatitis_b_surface_antibody_laboratory/\n",
      "Starting job 855b0f3f-a556-4d00-a43f-d167f4e48fc6\n",
      "Job finished.\n",
      "Table Row Count 103028 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hepatitis_b_surface_antibody_laboratory_20231110_191314.csv uploaded to nhanes_clean / hepatitis_b_surface_antibody_laboratory/\n",
      "Starting job cda8b70f-5a83-4ca3-9d26-fcfff0024b29\n",
      "Job finished.\n",
      "Table Row Count 103028 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hepatitis_c_rna_hcv_rna_confirmed_antibody_inno_lia_genotype_laboratory_20231110_191323.csv uploaded to nhanes_clean / hepatitis_c_rna_hcv_rna_confirmed_antibody_inno_lia_genotype_laboratory/\n",
      "Starting job baf587e8-9ab4-427f-8c61-a7ed5d463ad1\n",
      "Job finished.\n",
      "Table Row Count 19633 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hepatitis_e_igg_igm_antibodies_laboratory_20231110_191330.csv uploaded to nhanes_clean / hepatitis_e_igg_igm_antibodies_laboratory/\n",
      "Starting job 1644b5fb-0bcc-400b-b20b-5d05ca89dae0\n",
      "Job finished.\n",
      "Table Row Count 52357 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_sensitivity_c_reactive_protein_laboratory_20231110_191336.csv uploaded to nhanes_clean / high_sensitivity_c_reactive_protein_laboratory/\n",
      "Starting job b03fcd2f-7a76-496b-afcc-b32939b9e085\n",
      "Job finished.\n",
      "Table Row Count 22138 rows.\n",
      "Last 10 datasets took 1386.0373814105988 seconds\n",
      "hospital_utilization_access_to_care_questionnaire_20231110_191348.csv uploaded to nhanes_clean / hospital_utilization_access_to_care_questionnaire/\n",
      "Starting job 5101db9b-1c97-4399-b8ba-901f91a77448\n",
      "Job finished.\n",
      "Table Row Count 116876 rows.\n",
      "housing_characteristics_questionnaire_20231110_191404.csv uploaded to nhanes_clean / housing_characteristics_questionnaire/\n",
      "Starting job cc7fc7a2-5f85-4102-9aa8-5f1e0c9b5ff7\n",
      "Job finished.\n",
      "Table Row Count 101316 rows.\n",
      "immunization_questionnaire_20231110_191418.csv uploaded to nhanes_clean / immunization_questionnaire/\n",
      "Starting job c83ba971-b687-4f8b-94a5-b00557d892f2\n",
      "Job finished.\n",
      "Table Row Count 116876 rows.\n",
      "income_questionnaire_20231110_191432.csv uploaded to nhanes_clean / income_questionnaire/\n",
      "Starting job 14e62eaa-362a-4e2c-b9b4-3ad049ab0a75\n",
      "Job finished.\n",
      "Table Row Count 75402 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insulin_laboratory_20231110_191441.csv uploaded to nhanes_clean / insulin_laboratory/\n",
      "Starting job 3c6d90bb-860c-4b6b-b890-f7e3575a5ad7\n",
      "Job finished.\n",
      "Table Row Count 14646 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iodine_urine_laboratory_20231110_191450.csv uploaded to nhanes_clean / iodine_urine_laboratory/\n",
      "Starting job 8195386b-2d6d-42a0-a8e2-1014a2c0b297\n",
      "Job finished.\n",
      "Table Row Count 35880 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iron_status_serum_laboratory_20231110_191456.csv uploaded to nhanes_clean / iron_status_serum_laboratory/\n",
      "Starting job c8fdd710-343f-4dca-afbd-58d19bf48ecb\n",
      "Job finished.\n",
      "Table Row Count 16810 rows.\n",
      "kidney_conditions_urology_questionnaire_20231110_191505.csv uploaded to nhanes_clean / kidney_conditions_urology_questionnaire/\n",
      "Starting job ff94b4fe-f919-474d-87dd-85c94cc77735\n",
      "Job finished.\n",
      "Table Row Count 59433 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_cadmium_total_mercury_selenium_manganese_blood_laboratory_20231110_191514.csv uploaded to nhanes_clean / lead_cadmium_total_mercury_selenium_manganese_blood_laboratory/\n",
      "Starting job 8688416a-3a71-4ec6-9ad7-046f0627a11e\n",
      "Job finished.\n",
      "Table Row Count 27953 rows.\n",
      "medical_conditions_questionnaire_20231110_191526.csv uploaded to nhanes_clean / medical_conditions_questionnaire/\n",
      "Starting job 225ee409-8293-45f8-b592-c7da6c8b26a3\n",
      "Job finished.\n",
      "Table Row Count 111797 rows.\n",
      "Last 10 datasets took 1507.734755039215 seconds\n",
      "mental_health_depression_screener_questionnaire_20231110_191548.csv uploaded to nhanes_clean / mental_health_depression_screener_questionnaire/\n",
      "Starting job 804504c6-dab8-4e16-ae9f-22fe84caa271\n",
      "Job finished.\n",
      "Table Row Count 49461 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mercury_inorganic_urine_laboratory_20231110_191558.csv uploaded to nhanes_clean / mercury_inorganic_urine_laboratory/\n",
      "Starting job a768b67e-53cc-48b0-b766-82c751c2939d\n",
      "Job finished.\n",
      "Table Row Count 27523 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mercury_inorganic_ethyl_and_methyl_blood_laboratory_20231110_191605.csv uploaded to nhanes_clean / mercury_inorganic_ethyl_and_methyl_blood_laboratory/\n",
      "Starting job 17482153-91e1-41fe-9e32-f6ac68893d52\n",
      "Job finished.\n",
      "Table Row Count 29069 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metals_urine_laboratory_20231110_191614.csv uploaded to nhanes_clean / metals_urine_laboratory/\n",
      "Starting job 510c6427-0b3e-4663-8ca2-0223c9378d42\n",
      "Job finished.\n",
      "Table Row Count 32874 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nickel_urine_laboratory_20231110_191622.csv uploaded to nhanes_clean / nickel_urine_laboratory/\n",
      "Starting job c3666df5-ed89-4b4b-80f6-291050b5c2e9\n",
      "Job finished.\n",
      "Table Row Count 7869 rows.\n",
      "occupation_questionnaire_20231110_191630.csv uploaded to nhanes_clean / occupation_questionnaire/\n",
      "Starting job 6857d1ae-9fdc-4b30-b2f1-097763cfa736\n",
      "Job finished.\n",
      "Table Row Count 75038 rows.\n",
      "oral_health_questionnaire_20231110_191644.csv uploaded to nhanes_clean / oral_health_questionnaire/\n",
      "Starting job 1dc44e61-6295-4fc7-8245-69e617850e5e\n",
      "Job finished.\n",
      "Table Row Count 98221 rows.\n",
      "osteoporosis_questionnaire_20231110_191702.csv uploaded to nhanes_clean / osteoporosis_questionnaire/\n",
      "Starting job d90ab0ae-ede4-43f3-b633-f4e985639df9\n",
      "Job finished.\n",
      "Table Row Count 44335 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perchlorate_nitrate_thiocyanate_urine_laboratory_20231110_191716.csv uploaded to nhanes_clean / perchlorate_nitrate_thiocyanate_urine_laboratory/\n",
      "Starting job 442bcab0-ea58-4ae6-bcd1-2a7aacb6009b\n",
      "Job finished.\n",
      "Table Row Count 35656 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perfluoroalkyl_and_polyfluoroalkyl_substances_laboratory_20231110_191724.csv uploaded to nhanes_clean / perfluoroalkyl_and_polyfluoroalkyl_substances_laboratory/\n",
      "Starting job 4429f307-0ca3-41a6-b6fa-d15c28767edb\n",
      "Job finished.\n",
      "Table Row Count 4461 rows.\n",
      "Last 10 datasets took 1611.2208850383759 seconds\n",
      "perfluoroalkyl_and_polyfluoroalkyl_substances_surplus_laboratory_20231110_191729.csv uploaded to nhanes_clean / perfluoroalkyl_and_polyfluoroalkyl_substances_surplus_laboratory/\n",
      "Starting job 683e2b94-1fc2-43f8-829a-ee0efdb12403\n",
      "Job finished.\n",
      "Table Row Count 1672 rows.\n",
      "pesticide_use_questionnaire_20231110_191737.csv uploaded to nhanes_clean / pesticide_use_questionnaire/\n",
      "Starting job 7f55e5fe-d4be-4f15-9184-753c861f67b4\n",
      "Job finished.\n",
      "Table Row Count 99701 rows.\n",
      "physical_activity_questionnaire_20231110_191753.csv uploaded to nhanes_clean / physical_activity_questionnaire/\n",
      "Starting job 8b61da53-32d9-4726-b34c-a82541f49aa7\n",
      "Job finished.\n",
      "Table Row Count 100509 rows.\n",
      "physical_activity_youth_questionnaire_20231110_191807.csv uploaded to nhanes_clean / physical_activity_youth_questionnaire/\n",
      "Starting job 97d3d8e0-f98c-45bc-bd91-33b449b9c4ae\n",
      "Job finished.\n",
      "Table Row Count 7591 rows.\n",
      "physical_functioning_questionnaire_20231110_191816.csv uploaded to nhanes_clean / physical_functioning_questionnaire/\n",
      "Starting job b4945db8-248d-43d6-8431-f04b5b52a4cf\n",
      "Job finished.\n",
      "Table Row Count 93104 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plasma_fasting_glucose_laboratory_20231110_191832.csv uploaded to nhanes_clean / plasma_fasting_glucose_laboratory/\n",
      "Starting job 7cfaf1c5-8e82-430c-ba19-bb1170d70330\n",
      "Job finished.\n",
      "Table Row Count 14646 rows.\n",
      "'utf-8' codec can't decode byte 0xf6 in position 18: invalid start byte\n",
      "Unable to convert data types from bytes to string for: Prescription Medications - Questionnaire\n",
      "prescription_medications_questionnaire_20231110_191846.csv uploaded to nhanes_clean / prescription_medications_questionnaire/\n",
      "Starting job 683cacb8-3f49-4c7c-b25d-9233786f99f5\n",
      "Job finished.\n",
      "Table Row Count 223038 rows.\n",
      "preventive_aspirin_use_questionnaire_20231110_191904.csv uploaded to nhanes_clean / preventive_aspirin_use_questionnaire/\n",
      "Starting job f9ac7178-697c-4007-99ce-8ea26cf204fb\n",
      "Job finished.\n",
      "Table Row Count 21499 rows.\n",
      "reproductive_health_questionnaire_20231110_191914.csv uploaded to nhanes_clean / reproductive_health_questionnaire/\n",
      "Starting job fc50daf8-a3de-4f58-8dde-59063319807a\n",
      "Job finished.\n",
      "Table Row Count 40759 rows.\n",
      "sleep_disorders_questionnaire_20231110_191925.csv uploaded to nhanes_clean / sleep_disorders_questionnaire/\n",
      "Starting job b5b21d3b-676f-4b37-a724-c8a9da5c3374\n",
      "Job finished.\n",
      "Table Row Count 54896 rows.\n",
      "Last 10 datasets took 1738.1178879737854 seconds\n",
      "smoking_cigarette_use_questionnaire_20231110_191939.csv uploaded to nhanes_clean / smoking_cigarette_use_questionnaire/\n",
      "Starting job d2321239-a064-4e3d-8f7c-fffc78b412a5\n",
      "Job finished.\n",
      "Table Row Count 60679 rows.\n",
      "smoking_household_smokers_questionnaire_20231110_191951.csv uploaded to nhanes_clean / smoking_household_smokers_questionnaire/\n",
      "Starting job 2db5dacc-9db2-46db-9de0-cf8a018dd0ab\n",
      "Job finished.\n",
      "Table Row Count 116876 rows.\n",
      "smoking_recent_tobacco_use_questionnaire_20231110_192006.csv uploaded to nhanes_clean / smoking_recent_tobacco_use_questionnaire/\n",
      "Starting job 5fd80fb4-b668-495c-951f-446291074df3\n",
      "Job finished.\n",
      "Table Row Count 58348 rows.\n",
      "smoking_secondhand_smoke_exposure_questionnaire_20231110_192015.csv uploaded to nhanes_clean / smoking_secondhand_smoke_exposure_questionnaire/\n",
      "Starting job 9c505ca2-2da3-4f7a-91c9-848ada17cf85\n",
      "Job finished.\n",
      "Table Row Count 44960 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard_biochemistry_profile_laboratory_20231110_192024.csv uploaded to nhanes_clean / standard_biochemistry_profile_laboratory/\n",
      "Starting job a0044f8e-e1eb-46e9-87d4-12f6634feaaf\n",
      "Job finished.\n",
      "Table Row Count 72783 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transferrin_receptor_laboratory_20231110_192038.csv uploaded to nhanes_clean / transferrin_receptor_laboratory/\n",
      "Starting job 5b7d0bfe-8769-4be8-b507-9ce912dff72e\n",
      "Job finished.\n",
      "Table Row Count 25761 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urine_flow_rate_laboratory_20231110_192046.csv uploaded to nhanes_clean / urine_flow_rate_laboratory/\n",
      "Starting job b8984a57-e7d7-40e5-bc1c-a0dd999a5344\n",
      "Job finished.\n",
      "Table Row Count 54274 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urine_pregnancy_test_laboratory_20231110_192053.csv uploaded to nhanes_clean / urine_pregnancy_test_laboratory/\n",
      "Starting job ca7f5e76-dfd0-4496-8535-3fb1ceed4eca\n",
      "Job finished.\n",
      "Table Row Count 2807 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vitamin_c_laboratory_20231110_192059.csv uploaded to nhanes_clean / vitamin_c_laboratory/\n",
      "Starting job 3b666405-87af-442d-9e2d-f473167155f6\n",
      "Job finished.\n",
      "Table Row Count 23503 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volatile_organic_compound_voc_metabolites_urine_laboratory_20231110_192105.csv uploaded to nhanes_clean / volatile_organic_compound_voc_metabolites_urine_laboratory/\n",
      "Starting job bc94279b-bff9-42ed-869f-a51685eb3260\n",
      "Job finished.\n",
      "Table Row Count 16454 rows.\n",
      "Last 10 datasets took 1835.585443496704 seconds\n",
      "volatile_organic_compound_voc_metabolites_ii_urine_laboratory_20231110_192113.csv uploaded to nhanes_clean / volatile_organic_compound_voc_metabolites_ii_urine_laboratory/\n",
      "Starting job 800726cb-bbac-4c4c-ac7a-cb449aa03eae\n",
      "Job finished.\n",
      "Table Row Count 4890 rows.\n",
      "volatile_organic_compound_voc_metabolites_ii_urine_surplus_laboratory_20231110_192117.csv uploaded to nhanes_clean / volatile_organic_compound_voc_metabolites_ii_urine_surplus_laboratory/\n",
      "Starting job ec8578e6-d481-4f5d-94d6-9b88b098ae77\n",
      "Job finished.\n",
      "Table Row Count 2979 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_50151/2626580201.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volatile_organic_compounds_and_trihalomethanes_mtbe_blood_laboratory_20231110_192122.csv uploaded to nhanes_clean / volatile_organic_compounds_and_trihalomethanes_mtbe_blood_laboratory/\n",
      "Starting job 94ebc1ee-7c96-421c-b574-796730981bd7\n",
      "Job finished.\n",
      "Table Row Count 15251 rows.\n",
      "volatile_toxicant_questionnaire_20231110_192134.csv uploaded to nhanes_clean / volatile_toxicant_questionnaire/\n",
      "Starting job 85ae842b-0409-47db-a37d-50c2f3870da3\n",
      "Job finished.\n",
      "Table Row Count 11762 rows.\n",
      "weight_history_questionnaire_20231110_192145.csv uploaded to nhanes_clean / weight_history_questionnaire/\n",
      "Starting job bd3fcaec-c06e-42de-b21a-fbb8730029e5\n",
      "Job finished.\n",
      "Table Row Count 73787 rows.\n",
      "weight_history_youth_questionnaire_20231110_192159.csv uploaded to nhanes_clean / weight_history_youth_questionnaire/\n",
      "Starting job c020ea7e-0df2-4518-bb60-3196eff4edd8\n",
      "Job finished.\n",
      "Table Row Count 12777 rows.\n",
      "Entire process took 1885.296294927597 seconds\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "start_time = time.time()\n",
    "new_time = time.time()\n",
    "\n",
    "metadata_cols = ['start_year','end_year','last_updated','published_date','parquet_filename','data_file_url','doc_file_url','dataset']\n",
    "\n",
    "for data_file_name, page_component in file_subset_df.sort_values(by='data_file_name').values:\n",
    "    file_df = metadata_df[(metadata_df['data_file_name'] == data_file_name.strip()) &\n",
    "                          (metadata_df['page_component'].str.contains(page_component.strip()))]\n",
    "    if file_df['start_year'].max() > 2015:\n",
    "        \n",
    "        alias = generate_filename(data_file_name.lower() + \" \" + page_component.lower(),'')\n",
    "        \n",
    "        df = duckdb.read_parquet(f's3://{bucket_name}/all-continuous-nhanes/data/{alias}*.parquet',\n",
    "                    union_by_name=True,\n",
    "                    filename=True).to_df()\n",
    "        \n",
    "        df['survey'] = data_file_name\n",
    "        df['survey_type'] = page_component\n",
    "        if 'SEQN' in df.columns:\n",
    "            df['SEQN'] = df['SEQN'].astype('Int64')  \n",
    "        \n",
    "        df['filename_only'] = df['filename'].apply(lambda x: x.split('/')[-1])\n",
    "        \n",
    "        df = df.merge(metadata_df[metadata_cols],\n",
    "                 how='left',left_on='filename_only',right_on='parquet_filename')\n",
    "        \n",
    "        df['start_year'] = df['start_year'].astype('Int64')\n",
    "        df['end_year'] = df['end_year'].astype('Int64')\n",
    "        df['published_date'] = pd.to_datetime(df['published_date'],errors='ignore')\n",
    "        \n",
    "        df.drop(['filename_only'],axis=1, inplace=True)\n",
    "        \n",
    "        try:\n",
    "            str_df = df.select_dtypes([object])\n",
    "            str_df = str_df.stack().str.decode('utf-8').unstack()\n",
    "        \n",
    "            for col in str_df.columns:\n",
    "                if col not in metadata_cols and col != 'filename':\n",
    "                    df[col] = str_df[col]\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            print(f\"Unable to convert data types from bytes to string for: {data_file_name} - {page_component}\") \n",
    "\n",
    "        update_bq_table(\n",
    "                        df,\n",
    "                        alias,\n",
    "                        dataset=\"nhanes\",\n",
    "                        bucket=\"nhanes_clean\",\n",
    "                        truncate=True,\n",
    "                        max_error=0,\n",
    "                        schema=None,\n",
    "                    )\n",
    "        i += 1\n",
    "    \n",
    "        if i % 10 == 0 and i > 0:\n",
    "            print(f\"Last 10 datasets took {time.time() - new_time} seconds\")\n",
    "            \n",
    "print(f\"Entire process took {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d236f8-9b1a-466a-827f-810aace4d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_df.values[2][1].decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "352bb2cb-d408-4be6-9e40-75637732fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd14455c-372b-4000-99c4-3b3c577db952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DRXFCSD'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "881af620-35a2-4c1f-99d0-1da7a89584f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226     acculturation_questionnaire_*.parquet\n",
       "449     acculturation_questionnaire_*.parquet\n",
       "534     acculturation_questionnaire_*.parquet\n",
       "1049    acculturation_questionnaire_*.parquet\n",
       "1077    acculturation_questionnaire_*.parquet\n",
       "1164    acculturation_questionnaire_*.parquet\n",
       "1187    acculturation_questionnaire_*.parquet\n",
       "1329    acculturation_questionnaire_*.parquet\n",
       "1349    acculturation_questionnaire_*.parquet\n",
       "1395    acculturation_questionnaire_*.parquet\n",
       "1475    acculturation_questionnaire_*.parquet\n",
       "Name: gcs_data_filename, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file_df['gcs_data_filename'].apply(lambda x: x.split('all_continuous')[0] + '*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f611e7a-b482-456c-9fde-481e9226cd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>ACD010A</th>\n",
       "      <th>ACD010B</th>\n",
       "      <th>ACD010C</th>\n",
       "      <th>ACQ020</th>\n",
       "      <th>ACQ030</th>\n",
       "      <th>ACD040</th>\n",
       "      <th>ACQ050</th>\n",
       "      <th>ACQ060</th>\n",
       "      <th>ACD070</th>\n",
       "      <th>ACD080</th>\n",
       "      <th>ACD011A</th>\n",
       "      <th>ACD011B</th>\n",
       "      <th>ACD011C</th>\n",
       "      <th>ACD110</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92153</th>\n",
       "      <td>124817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92154</th>\n",
       "      <td>124818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92155</th>\n",
       "      <td>124820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92156</th>\n",
       "      <td>124821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92157</th>\n",
       "      <td>124822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes_clean/all-continuous-nhanes/data/a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92158 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEQN  ACD010A  ACD010B  ACD010C  ACQ020  ACQ030  ACD040  ACQ050  \\\n",
       "0           2      1.0      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "1           5      1.0      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "2           6      1.0      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "3           7      1.0      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "4           8      1.0      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "...       ...      ...      ...      ...     ...     ...     ...     ...   \n",
       "92153  124817      NaN      NaN      NaN     NaN     NaN     2.0     NaN   \n",
       "92154  124818      NaN      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "92155  124820      NaN      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "92156  124821      NaN      NaN      NaN     NaN     NaN     NaN     NaN   \n",
       "92157  124822      NaN      NaN      NaN     NaN     NaN     3.0     NaN   \n",
       "\n",
       "       ACQ060  ACD070  ACD080  ACD011A  ACD011B  ACD011C  ACD110  \\\n",
       "0         NaN     NaN     NaN      NaN      NaN      NaN     NaN   \n",
       "1         NaN     NaN     NaN      NaN      NaN      NaN     NaN   \n",
       "2         NaN     NaN     NaN      NaN      NaN      NaN     NaN   \n",
       "3         NaN     NaN     NaN      NaN      NaN      NaN     NaN   \n",
       "4         NaN     NaN     NaN      NaN      NaN      NaN     NaN   \n",
       "...       ...     ...     ...      ...      ...      ...     ...   \n",
       "92153     NaN     NaN     NaN      NaN      NaN      NaN     NaN   \n",
       "92154     NaN     NaN     NaN      1.0      NaN      NaN     NaN   \n",
       "92155     NaN     NaN     NaN      1.0      NaN      NaN     NaN   \n",
       "92156     NaN     NaN     NaN      1.0      NaN      NaN     NaN   \n",
       "92157     NaN     NaN     NaN      NaN      NaN      NaN     NaN   \n",
       "\n",
       "                                                filename  \n",
       "0      s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "1      s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "2      s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "3      s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "4      s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "...                                                  ...  \n",
       "92153  s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "92154  s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "92155  s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "92156  s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "92157  s3://nhanes_clean/all-continuous-nhanes/data/a...  \n",
       "\n",
       "[92158 rows x 16 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec65e8d0-3aa0-431c-9a40-ebb3b75e7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df['gcs_data_filename'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67d71387-027d-4f55-8c98-ff19c78f2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df[metadata_df['gcs_data_filename'].str.contains('audiometry_all_continuous_nhanes_1999_2000_data.parquet')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0e3affd6-c7ca-4c8d-8e18-84402a7355ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['physical_activity_monitor_raw_data_80hz_examination_all_continuous_nhanes_2013_2014_data.XPT',\n",
       " 'physical_activity_monitor_raw_data_80hz_examination_all_continuous_nhanes_2011_2012_data.XPT']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_df.sort_values(by=['start_year','end_year','data_file_name'], ascending=False).drop_duplicates(subset=['gcs_data_filename'])['gcs_data_filename'].tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e86e98f-fb14-4835-b980-936dd1e9c3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Success]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0ddea-c90a-4666-ad51-53a0c5ef290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "output_df << SELECT * FROM read_parquet(f's3://nhanes/all-continuous-nhanes/data/audiometry_all*.parquet',\n",
    "                                           union_by_name=True,\n",
    "                                           filename=true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef03cedc-ef64-4d53-87ce-efc66845b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df['filename_only'] = output_df['filename'].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a8ec865-b64a-444b-80de-71ecc82e71ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_df['filename_only'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b379643-ab27-4929-b92b-3404b836e9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>AUQ130</th>\n",
       "      <th>AUQ140</th>\n",
       "      <th>AUQ150</th>\n",
       "      <th>AUQ160</th>\n",
       "      <th>AUQ170</th>\n",
       "      <th>AUQ180</th>\n",
       "      <th>AUQ190</th>\n",
       "      <th>AUQ200</th>\n",
       "      <th>AUQ210</th>\n",
       "      <th>...</th>\n",
       "      <th>AUQ490</th>\n",
       "      <th>AUQ500</th>\n",
       "      <th>AUQ510</th>\n",
       "      <th>filename</th>\n",
       "      <th>filename_only</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>published_date</th>\n",
       "      <th>parquet_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2023-11-07 21:25:40.087858+00:00</td>\n",
       "      <td>2005-02-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2023-11-07 21:25:42.493038+00:00</td>\n",
       "      <td>2002-06-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2023-11-07 21:25:40.087858+00:00</td>\n",
       "      <td>2005-02-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2023-11-07 21:25:42.493038+00:00</td>\n",
       "      <td>2002-06-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2023-11-07 21:25:40.087858+00:00</td>\n",
       "      <td>2005-02-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_1999_2000_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204049</th>\n",
       "      <td>124820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2023-11-07 21:25:42.493038+00:00</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204050</th>\n",
       "      <td>124821.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2023-11-07 21:25:40.087858+00:00</td>\n",
       "      <td>2022-03-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204051</th>\n",
       "      <td>124821.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2023-11-07 21:25:42.493038+00:00</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204052</th>\n",
       "      <td>124822.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2023-11-07 21:25:40.087858+00:00</td>\n",
       "      <td>2022-03-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204053</th>\n",
       "      <td>124822.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://nhanes/all-continuous-nhanes/data/audiome...</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2023-11-07 21:25:42.493038+00:00</td>\n",
       "      <td>2021-09-01 00:00:00</td>\n",
       "      <td>audiometry_all_continuous_nhanes_2017_2020_dat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204054 rows  95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SEQN  AUQ130  AUQ140  AUQ150  AUQ160  AUQ170  AUQ180  AUQ190  \\\n",
       "0            1.0     1.0     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1            1.0     1.0     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2            2.0     2.0     4.0     2.0     NaN     NaN     NaN     2.0   \n",
       "3            2.0     2.0     4.0     2.0     NaN     NaN     NaN     2.0   \n",
       "4            3.0     1.0     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...          ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "204049  124820.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "204050  124821.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "204051  124821.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "204052  124822.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "204053  124822.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "        AUQ200  AUQ210  ...  AUQ490  AUQ500  AUQ510  \\\n",
       "0          NaN     NaN  ...     NaN     NaN     NaN   \n",
       "1          NaN     NaN  ...     NaN     NaN     NaN   \n",
       "2          NaN     2.0  ...     NaN     NaN     NaN   \n",
       "3          NaN     2.0  ...     NaN     NaN     NaN   \n",
       "4          NaN     NaN  ...     NaN     NaN     NaN   \n",
       "...        ...     ...  ...     ...     ...     ...   \n",
       "204049     NaN     NaN  ...     NaN     NaN     NaN   \n",
       "204050     NaN     NaN  ...     NaN     NaN     NaN   \n",
       "204051     NaN     NaN  ...     NaN     NaN     NaN   \n",
       "204052     NaN     NaN  ...     2.0     NaN     NaN   \n",
       "204053     NaN     NaN  ...     2.0     NaN     NaN   \n",
       "\n",
       "                                                 filename  \\\n",
       "0       s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "1       s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "2       s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "3       s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "4       s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "...                                                   ...   \n",
       "204049  s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "204050  s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "204051  s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "204052  s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "204053  s3://nhanes/all-continuous-nhanes/data/audiome...   \n",
       "\n",
       "                                            filename_only  start_year  \\\n",
       "0       audiometry_all_continuous_nhanes_1999_2000_dat...      1999.0   \n",
       "1       audiometry_all_continuous_nhanes_1999_2000_dat...      1999.0   \n",
       "2       audiometry_all_continuous_nhanes_1999_2000_dat...      1999.0   \n",
       "3       audiometry_all_continuous_nhanes_1999_2000_dat...      1999.0   \n",
       "4       audiometry_all_continuous_nhanes_1999_2000_dat...      1999.0   \n",
       "...                                                   ...         ...   \n",
       "204049  audiometry_all_continuous_nhanes_2017_2020_dat...      2017.0   \n",
       "204050  audiometry_all_continuous_nhanes_2017_2020_dat...      2017.0   \n",
       "204051  audiometry_all_continuous_nhanes_2017_2020_dat...      2017.0   \n",
       "204052  audiometry_all_continuous_nhanes_2017_2020_dat...      2017.0   \n",
       "204053  audiometry_all_continuous_nhanes_2017_2020_dat...      2017.0   \n",
       "\n",
       "        end_year                     last_updated       published_date  \\\n",
       "0         2000.0 2023-11-07 21:25:40.087858+00:00  2005-02-01 00:00:00   \n",
       "1         2000.0 2023-11-07 21:25:42.493038+00:00  2002-06-01 00:00:00   \n",
       "2         2000.0 2023-11-07 21:25:40.087858+00:00  2005-02-01 00:00:00   \n",
       "3         2000.0 2023-11-07 21:25:42.493038+00:00  2002-06-01 00:00:00   \n",
       "4         2000.0 2023-11-07 21:25:40.087858+00:00  2005-02-01 00:00:00   \n",
       "...          ...                              ...                  ...   \n",
       "204049    2020.0 2023-11-07 21:25:42.493038+00:00  2021-09-01 00:00:00   \n",
       "204050    2020.0 2023-11-07 21:25:40.087858+00:00  2022-03-01 00:00:00   \n",
       "204051    2020.0 2023-11-07 21:25:42.493038+00:00  2021-09-01 00:00:00   \n",
       "204052    2020.0 2023-11-07 21:25:40.087858+00:00  2022-03-01 00:00:00   \n",
       "204053    2020.0 2023-11-07 21:25:42.493038+00:00  2021-09-01 00:00:00   \n",
       "\n",
       "                                         parquet_filename  \n",
       "0       audiometry_all_continuous_nhanes_1999_2000_dat...  \n",
       "1       audiometry_all_continuous_nhanes_1999_2000_dat...  \n",
       "2       audiometry_all_continuous_nhanes_1999_2000_dat...  \n",
       "3       audiometry_all_continuous_nhanes_1999_2000_dat...  \n",
       "4       audiometry_all_continuous_nhanes_1999_2000_dat...  \n",
       "...                                                   ...  \n",
       "204049  audiometry_all_continuous_nhanes_2017_2020_dat...  \n",
       "204050  audiometry_all_continuous_nhanes_2017_2020_dat...  \n",
       "204051  audiometry_all_continuous_nhanes_2017_2020_dat...  \n",
       "204052  audiometry_all_continuous_nhanes_2017_2020_dat...  \n",
       "204053  audiometry_all_continuous_nhanes_2017_2020_dat...  \n",
       "\n",
       "[204054 rows x 95 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.merge(metadata_df[['start_year','end_year','last_updated','published_date','parquet_filename']],how='left',left_on='filename_only',right_on='parquet_filename')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "nhanes",
   "name": "pytorch-gpu.2-0.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m112"
  },
  "kernelspec": {
   "display_name": "nhanes",
   "language": "python",
   "name": "nhanes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
